{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ibtewlgs7",
   "metadata": {},
   "source": [
    "# Lab 01: System Inference Profiles\n",
    "\n",
    "## Business Context\n",
    "\n",
    "You are **Alex, Platform Engineer at AnyCompany Solutions**, a SaaS company building a **Multi-Tenant Marketing Platform** that serves **multiple enterprise customers**. Your platform uses Claude Sonnet 4.0 to generate intelligent responses for various customer workloads.\n",
    "\n",
    "**Current Setup:**\n",
    "- Using AWS Bedrock with **System Inference Profiles**\n",
    "- Multiple enterprise customers sharing the same model endpoint\n",
    "- All customers route through `us.anthropic.claude-sonnet-4-20250514-v1:0`\n",
    "\n",
    "**The Problem You're Facing:**\n",
    "\n",
    "Your CEO just asked three critical questions:\n",
    "\n",
    "1. **üí∞ \"How much does each customer cost us in AI spending?\"**\n",
    "   - You can't answer - all usage is aggregated together\n",
    "   \n",
    "2. **üìä \"Which customers are heavy users vs light users?\"**\n",
    "   - You don't know - no per-customer visibility\n",
    "   \n",
    "3. **üéØ \"Can we implement usage-based pricing?\"**\n",
    "   - Not reliably - you can't track individual customer usage\n",
    "\n",
    "**The Root Cause: System Inference Profiles**\n",
    "\n",
    "When you use System Inference Profiles, AWS Bedrock treats all requests the same:\n",
    "- ‚ùå No tenant identification in metrics\n",
    "- ‚ùå No way to separate customer A's usage from customer B's\n",
    "- ‚ùå CloudWatch metrics show only aggregated totals\n",
    "- ‚ùå Impossible to implement accurate billing per customer\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you'll understand:\n",
    "- How System Inference Profiles work (and their limitations)\n",
    "- Why multi-tenant applications can't track per-customer metrics with System Inference Profiles\n",
    "- What CloudWatch metrics look like with System Inference Profiles (aggregated data)\n",
    "- The business impact of not having tenant-level visibility\n",
    "\n",
    "## What You'll Do\n",
    "\n",
    "1. **üîß Make a model inference call** using System Inference Profile\n",
    "2. **üìä Check CloudWatch metrics** and see aggregated (not separated) data\n",
    "3. **‚ùå Experience the problem firsthand** - no way to attribute usage to specific customers\n",
    "4. **üí° Understand why** this is a showstopper for multi-tenant SaaS platforms\n",
    "\n",
    "**Ready to see the problem?** Let's start by making an inference call using System Inference Profiles..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12decf4",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Configuration\n",
    "\n",
    "First, let's import the necessary libraries and configure our AWS Bedrock client with a **System Inference Profile** (the traditional approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install --force-reinstall -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime, time\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_helpers.config import Region, ModelId, Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beylqdq9nuv",
   "metadata": {},
   "source": [
    "### üìã Configuration Check\n",
    "\n",
    "Let's verify our configuration from the lab helpers:\n",
    "- **Region**: AWS region where Bedrock is available\n",
    "- **ModelId**: System Inference Profile ID (shared across all customers)\n",
    "- **Prompt**: Sample prompt to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179956f-7b2c-4a0a-9f39-58e6eb7003c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AWS Region is {Region}\")\n",
    "print(f\"Model ID is {ModelId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efozkl7muq",
   "metadata": {},
   "source": [
    "## Section 2: Make Inference Call with System Inference \n",
    "\n",
    "  ### ü§ñ The Problem in Action\n",
    "\n",
    "  Let's simulate what happens when multiple tenants use your platform with a **System Inference Profile**:\n",
    "\n",
    "  - **Tenant A (B2B)**: Requests campaign for DevOps platform\n",
    "  - **Tenant B (B2C)**: Requests campaign for fashion collection\n",
    "\n",
    "  **‚ùå The Critical Issue:**\n",
    "  Both tenants call the **same** `modelId` - there's no way to distinguish their usage in CloudWatch!\n",
    "\n",
    "  ```python\n",
    "  # Both tenants use this:\n",
    "  modelId = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"\n",
    "\n",
    "  Result: All metrics are aggregated together.\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ada82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multi-tenant requests using System Inference Profile\n",
    "# In a real multi-tenant app, these would come from different customers\n",
    "\n",
    "# Define prompts for two tenants (same as Lab 03 context)\n",
    "TENANT_PROMPTS = {\n",
    "    \"tenant_a\": \"Generate a brief marketing campaign for a B2B SaaS DevOps automation platform targeting CTOs.\",\n",
    "    \"tenant_b\": \"Generate a brief marketing campaign for a B2C sustainable fashion collection targeting millennials.\"\n",
    "}\n",
    "\n",
    "# Create Bedrock runtime client\n",
    "bedrock = boto3.client('bedrock-runtime', region_name=Region)\n",
    "\n",
    "print(\"üîÑ Simulating requests from multiple tenants using System Inference Profile...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Make inference calls for both tenants\n",
    "for idx, (tenant_id, prompt) in enumerate(TENANT_PROMPTS.items()):\n",
    "    print(f\"\\nüè¢ Request from {tenant_id.upper()}:\")\n",
    "    print(f\"Prompt: {prompt[:80]}...\")\n",
    "    \n",
    "    # THE PROBLEM: Both tenants use the SAME modelId!\n",
    "    response = bedrock.converse(\n",
    "        modelId=ModelId,  # ‚ùå Same for all tenants - no way to distinguish!\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [{'text': prompt}]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract response\n",
    "    output = response['output']['message']['content'][0]['text']\n",
    "    usage = response['usage']\n",
    "    \n",
    "    print(f\"‚úÖ Response received\")\n",
    "    print(f\"   Input tokens: {usage['inputTokens']}\")\n",
    "    print(f\"   Output tokens: {usage['outputTokens']}\")\n",
    "    print(f\"   Response preview: {output[:100]}...\")\n",
    "\n",
    "    # Add 1-minute gap between tenant requests for CloudWatch visualization\n",
    "    if idx == 0:  # After first tenant only\n",
    "          print(f\"\\n‚è≥ Waiting 80 seconds before next request (for CloudWatch separation)...\")\n",
    "          time.sleep(60)\n",
    "          print(f\"‚úÖ Wait complete - proceeding with Tenant B request\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THE PROBLEM: Both tenant requests used the SAME modelId!\")\n",
    "print(f\"   ModelId: {ModelId}\")\n",
    "print(\"   All usage will be aggregated in CloudWatch - no way to separate!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g8rpp5kxo5o",
   "metadata": {},
   "source": [
    "## Section 3: Check CloudWatch Metrics - The Aggregation Problem\n",
    "\n",
    "### üìä CloudWatch Metrics Helper Function\n",
    "\n",
    "This function fetches CloudWatch metrics from AWS Bedrock for the System Inference Profile.\n",
    "\n",
    "**What it retrieves:**\n",
    "- **Invocations**: Total number of API calls (all customers combined)\n",
    "- **InputTokenCount**: Total input tokens processed (all customers combined)\n",
    "- **OutputTokenCount**: Total output tokens generated (all customers combined)\n",
    "\n",
    "**The Critical Limitation:**\n",
    "All metrics use the **same ModelId dimension** - the System Inference Profile ID. This means:\n",
    "- ‚ùå No way to filter by customer/tenant\n",
    "- ‚ùå No way to see which customer made which request\n",
    "- ‚ùå No way to allocate costs per customer\n",
    "\n",
    "**Dimension in CloudWatch:** `ModelId = us.anthropic.claude-sonnet-4-20250514-v1:0`\n",
    "\n",
    "This dimension is **shared by all customers**, making per-customer tracking impossible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff24e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CloudWatch client\n",
    "\n",
    "def fetch_metrices(Region, ModelId, Period=300, Timedelta=60):\n",
    "    \n",
    "    cloudwatch = boto3.client('cloudwatch', region_name=Region)\n",
    "    \n",
    "    # Get metrics for the last hour\n",
    "    #end_time = datetime.utcnow()\n",
    "    end_time=datetime.datetime.now(datetime.UTC)\n",
    "    start_time = end_time - timedelta(minutes=60)\n",
    "    \n",
    "    # Get Bedrock invocation metrics\n",
    "    #Invocations - Number of API calls\n",
    "    response = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/Bedrock',\n",
    "        MetricName='Invocations',\n",
    "        Dimensions=[\n",
    "            {\n",
    "                'Name': 'ModelId',\n",
    "                'Value': ModelId\n",
    "            }\n",
    "        ],\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,  # 1 minute\n",
    "        Statistics=['Sum']\n",
    "    )\n",
    "    \n",
    "    print(\"Invocation Count:\")\n",
    "    for datapoint in response['Datapoints']:\n",
    "        print(f\"Time: {datapoint['Timestamp']}, Count: {datapoint['Sum']}\")\n",
    "    \n",
    "    # Get input token metrics \n",
    "    # InputTokenCount - Total input tokens processed\n",
    "    \n",
    "    input_token_response = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/Bedrock',\n",
    "        MetricName='InputTokenCount',\n",
    "        Dimensions=[\n",
    "            {\n",
    "                'Name': 'ModelId',\n",
    "                'Value': ModelId\n",
    "            }\n",
    "        ],\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=['Sum']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nInput Token Count:\")\n",
    "    for datapoint in input_token_response['Datapoints']:\n",
    "        print(f\"Time: {datapoint['Timestamp']}, Tokens: {datapoint['Sum']}\")\n",
    "    \n",
    "    # Get output token metrics\n",
    "    #OutputTokenCount - Total output tokens generated\n",
    "    output_token_response = cloudwatch.get_metric_statistics(\n",
    "        Namespace='AWS/Bedrock',\n",
    "        MetricName='OutputTokenCount',\n",
    "        Dimensions=[\n",
    "            {\n",
    "                'Name': 'ModelId',\n",
    "                'Value': ModelId\n",
    "            }\n",
    "        ],\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=['Sum']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nOutput Token Count:\")\n",
    "    for datapoint in output_token_response['Datapoints']:\n",
    "        print(f\"Time: {datapoint['Timestamp']}, Tokens: {datapoint['Sum']}\")\n",
    "\n",
    "    return response,input_token_response,output_token_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9hhh4mppxtn",
   "metadata": {},
   "source": [
    "### üìà Visualize the Aggregated Metrics\n",
    "\n",
    "Let's fetch and plot the CloudWatch metrics for our System Inference Profile.\n",
    "\n",
    "**What you'll see:**\n",
    "- Combined metrics for all tenants (aggregated data)\n",
    "- No way to distinguish between different tenants\n",
    "- Single dimension: `ModelId = <system-inference-profile-id>`\n",
    "\n",
    "**The Multi-Tenant Problem Visualized:**\n",
    "\n",
    "Imagine if these metrics represented:\n",
    "- 60% Tenant A (B2B Tech - high-volume user)\n",
    "- 40% Tenant B (B2C Retail - medium-volume user)\n",
    "\n",
    "With System Inference Profiles, **you can't tell!** All usage is combined into one metric stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CloudWatch metrics After  campaign generation\n",
    "import time\n",
    "print(\"‚è≥ Waiting 60 seconds for CloudWatch metrics to propagate...\")\n",
    "time.sleep(60)\n",
    "print(\"‚úÖ Wait complete - proceeding with metrics monitoring\")\n",
    "\n",
    "# Create graphs\n",
    "\n",
    "response,input_token_response,output_token_response = fetch_metrices(Region, ModelId, 60, 60)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot Invocations\n",
    "inv_data = sorted(response['Datapoints'], key=lambda x: x['Timestamp'])\n",
    "inv_times = [dp['Timestamp'] for dp in inv_data]\n",
    "inv_values = [dp['Sum'] for dp in inv_data]\n",
    "axes[0].plot(inv_times, inv_values, marker='o', linewidth=2)  # Added linewidth\n",
    "axes[0].set_title('Invocations over 1 hour')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot Input Tokens\n",
    "input_data = sorted(input_token_response['Datapoints'], key=lambda x: x['Timestamp'])\n",
    "input_times = [dp['Timestamp'] for dp in input_data]\n",
    "input_values = [dp['Sum'] for dp in input_data]\n",
    "axes[1].plot(input_times, input_values, marker='o', color='green', linewidth=2)  # Added linewidth\n",
    "axes[1].set_title('Input Token Count over 1 hour')\n",
    "axes[1].set_ylabel('Tokens')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Plot Output Tokens\n",
    "output_data = sorted(output_token_response['Datapoints'], key=lambda x: x['Timestamp'])\n",
    "output_times = [dp['Timestamp'] for dp in output_data]\n",
    "output_values = [dp['Sum'] for dp in output_data]\n",
    "axes[2].plot(output_times, output_values, marker='o', color='red', linewidth=2)  # Added linewidth\n",
    "axes[2].set_title('Output Token Count over 1 hour')\n",
    "axes[2].set_ylabel('Tokens')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c85268-2c97-4076-8a80-140874aa76a2",
   "metadata": {},
   "source": [
    "## Lab Summary: The Multi-Tenant Metrics Problem\n",
    "\n",
    "### üéØ What You Experienced\n",
    "\n",
    "You just experienced the **fundamental limitation of System Inference Profiles** for multi-tenant applications:\n",
    "\n",
    "**‚ùå The Problem:**\n",
    "1. **All tenants share the same ModelId dimension** in CloudWatch\n",
    "2. **No way to separate metrics** by tenant\n",
    "3. **No way to track costs** per tenant\n",
    "4. **No way to implement usage-based billing** accurately\n",
    "5. **No way to monitor SLAs** per tenant\n",
    "\n",
    "### üìä What You Saw in CloudWatch\n",
    "\n",
    "```\n",
    "System Inference Profile Metrics:\n",
    "‚îú‚îÄ ModelId: us.anthropic.claude-sonnet-4-20250514-v1:0\n",
    "‚îÇ   ‚îú‚îÄ Invocations: >1 (but which tenant?)\n",
    "‚îÇ   ‚îú‚îÄ InputTokenCount: x (Tenant A? B?)\n",
    "‚îÇ   ‚îî‚îÄ OutputTokenCount: y (impossible to allocate!)\n",
    "```\n",
    "\n",
    "**The Reality:** These metrics represent **all tenants combined**. You cannot:\n",
    "- Filter by specific tenant\n",
    "- Calculate per-tenant costs\n",
    "- Identify high-usage tenants\n",
    "- Implement fair billing\n",
    "\n",
    "### üíº Business Impact\n",
    "\n",
    "As **Alex, the Platform Engineer**, you need to tell your CEO:\n",
    "\n",
    "1. **üí∞ Cost Allocation:** \"We can't determine individual tenant costs\"\n",
    "2. **üìä Usage Tracking:** \"We don't know which tenants are heavy users\"\n",
    "3. **üéØ Pricing Model:** \"We can't implement accurate usage-based pricing\"\n",
    "4. **üìâ SLA Monitoring:** \"We can't track performance per tenant\"\n",
    "\n",
    "**This is a showstopper for any multi-tenant SaaS business!**\n",
    "\n",
    "### üöÄ The Solution Preview\n",
    "\n",
    "In **Lab 02**, you'll discover **Application Inference Profiles (AIP)** - the solution that enables:\n",
    "\n",
    "‚úÖ **Per-tenant model access** with unique identifiers \n",
    "\n",
    "‚úÖ **Isolated CloudWatch metrics** for each tenant\n",
    "\n",
    "‚úÖ **Accurate cost tracking** per tenant\n",
    "\n",
    "‚úÖ **Usage-based billing** with confidence\n",
    "\n",
    "‚úÖ **Per-tenant SLA monitoring**\n",
    "\n",
    "**The key difference:**\n",
    "```python\n",
    "# System Inference Profile (Lab 01 - Problem)\n",
    "modelId = \"us.anthropic.claude-sonnet-4-20250514-v1:0\"  # Shared by all tenants\n",
    "\n",
    "# Application Inference Profile (Lab 02 - Solution)  \n",
    "tenant_a_modelId = \"arn:aws:bedrock:region:account:application-inference-profile/tenant-a\"  # Unique per tenant!\n",
    "tenant_b_modelId = \"arn:aws:bedrock:region:account:application-inference-profile/tenant-b\"  # Unique per tenant!\n",
    "```\n",
    "\n",
    "### üí° Key Takeaway\n",
    "\n",
    "**System Inference Profiles are great for:**\n",
    "- Single-tenant applications\n",
    "- Internal tools\n",
    "- Prototyping and development\n",
    "\n",
    "**But for multi-tenant SaaS platforms, you need Application Inference Profiles to:**\n",
    "- Track usage per tenant\n",
    "- Allocate costs accurately\n",
    "- Implement fair billing\n",
    "- Monitor SLAs per tenant\n",
    "\n",
    "**Ready to see the solution?** ‚Üí [Continue to Lab 02: Application Inference Profiles Solution](lab-02-aip-solution-and-crud.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgentCore Tutorials (Python 3)",
   "language": "python",
   "name": "agentcore-tutorials"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
